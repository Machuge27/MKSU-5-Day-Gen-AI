## Other Resources

### Day 2 (Embeddings and Vector Stores/Databases)

Welcome to Day 2.

Today you will learn about the conceptual underpinning of embeddings and vector databases and how they can be used to bring live or specialist data into your LLM application. You’ll also explore their geometrical powers for classifying and comparing textual data.

### Day 2 Assignments:

1. Complete Unit 2: “Embeddings and Vector Stores/Databases”, which is:
    - [Optional] Listen to the summary [podcast episode](https://youtube.com/watch?v=1CC39K76Nqs) for this unit (created by NotebookLM).
    - Read the “[Embeddings and Vector Stores/Databases](https://kaggle.com/whitepaper-embeddings-and-vector-stores)” whitepaper.
    - Complete these code labs on Kaggle:
      1. [Build](https://www.kaggle.com/code/markishere/day-2-document-q-a-with-rag) a RAG question-answering system over custom documents
      2. [Explore](https://www.kaggle.com/code/markishere/day-2-embeddings-and-similarity-scores) text similarity with embeddings
      3. [Build](https://www.kaggle.com/code/markishere/day-2-classifying-embeddings-with-keras) a neural classification network with Keras using embeddings
2. Watch [the YouTube livestream recording.](https://www.youtube.com/watch?v=86GZC56rQCc&list=PLqFaTIg4myu-b1PlxitQdY0UYIbys-2es&index=2) Paige Bailey will be joined by expert speakers from Google - Omid Fatemieh, Jinhyuk Lee, Alan Li, Iftekhar Naim, Anant Nawalgaria, Yan Qiao, and Xiaoqi Ren to discuss embeddings and vector stores/databases.